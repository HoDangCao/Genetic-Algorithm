{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticðŸ§¬Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Genetic Algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **genetic algorithm** is a search technique that **mimics natural selection** to find optimal solutions by iteratively refining a population of candidate solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use genetic algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- be beneficial in optimization issues when traditional methods fail.\n",
    "- efficiently navigate large and complex search spaces, making them ideal for tasks that require finding optimal solutions under restrictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Expression Programming (GEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is GEP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is a variant of genetic algorithms where individuals are encoded as linear strings of fixed length, which are then expressed as nonlinear entities of different sizes and shapes.\n",
    "\n",
    "GEP has shown effectiveness in solving complex problems because it combines the advantages of genetic algorithms and genetic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications of GEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Symbolic Regression: Discover mathematical models that best fit a set of data points.\n",
    "- Classification: Develop models to classify data into predefined categories.\n",
    "- Time Series Prediction: Forecast future values based on historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the genetic optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genetic optimization refers to the use of genetic algorithms to solve optimization problems. This process involves generating a population of possible solutions and iteratively improving them based on their performance against a defined objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm of Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate an initial population of potential solutions at random or using certain strategies. \n",
    "\n",
    "- The size of the population is an important parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- evaluates how well each individual in the population performs.\n",
    "- e.g., in the case of recommendation system, the fitness function was based on user engagement metrics such as click-through rates and user satisfaction scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose the best-performing individuals to act as parents for the next generation. The most common selection methods are:\n",
    "\n",
    "- Roulette Wheel Selection: Individuals are selected based on their fitness proportion.\n",
    "- Tournament Selection: A set of individuals is chosen randomly, and the best among them is selected.\n",
    "- Rank Selection: Individuals are ranked based on their fitness, and selection is based on these ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossover (recombination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the merging of two parent solutions to form offspring. Common crossover strategies include the following:\n",
    "\n",
    "1. Single-point crossover: select a crossover point and exchange the genes before and after this point between parents.\n",
    "2. Two-Point Crossover: Two crossover points are selected, and the genes between these points are exchanged.\n",
    "3. Parents randomly exchange genes in Uniform Crossover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Makes random changes to individual solutions in order to maintain variation in genetics. \n",
    "\n",
    "- Mutation rates must be carefully balanced so that appropriate exploration can be done while preserving good solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Termination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeats the process of selection, crossover, and mutation until a stopping criterion:\n",
    "- a predetermined number of generations\n",
    "- a certain fitness level\n",
    "- a lack of considerable improvement over future generations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation: Genetic Algorithm for Function Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1, Best Fitness: 1.3805798734864907\n",
      "Generation 2, Best Fitness: 1.8918933698527065\n",
      "Generation 3, Best Fitness: 2.272549162093107\n",
      "Generation 4, Best Fitness: 2.551340813154705\n",
      "Generation 5, Best Fitness: 3.1288981735058266\n",
      "Generation 6, Best Fitness: 3.6049920349176996\n",
      "Generation 7, Best Fitness: 4.177347905458683\n",
      "Generation 8, Best Fitness: 4.630325922407399\n",
      "Generation 9, Best Fitness: 5.089008404137174\n",
      "Generation 10, Best Fitness: 6.248126665139105\n",
      "Generation 11, Best Fitness: 6.97702731961774\n",
      "Generation 12, Best Fitness: 8.280769174704464\n",
      "Generation 13, Best Fitness: 9.411689105921049\n",
      "Generation 14, Best Fitness: 9.70377124693442\n",
      "Generation 15, Best Fitness: 10.419032672986253\n",
      "Generation 16, Best Fitness: 10.828679978910708\n",
      "Generation 17, Best Fitness: 11.776683762080092\n",
      "Generation 18, Best Fitness: 12.98318221402017\n",
      "Generation 19, Best Fitness: 13.537779560534759\n",
      "Generation 20, Best Fitness: 14.005319207874866\n",
      "Generation 21, Best Fitness: 14.700010958741165\n",
      "Generation 22, Best Fitness: 15.953984164649015\n",
      "Generation 23, Best Fitness: 17.361060150385924\n",
      "Generation 24, Best Fitness: 18.2797382585467\n",
      "Generation 25, Best Fitness: 19.117358325682517\n",
      "Generation 26, Best Fitness: 20.737130485471845\n",
      "Generation 27, Best Fitness: 21.92159652428214\n",
      "Generation 28, Best Fitness: 22.791863621140408\n",
      "Generation 29, Best Fitness: 25.74632785824551\n",
      "Generation 30, Best Fitness: 27.961834885797643\n",
      "Generation 31, Best Fitness: 29.42837835289631\n",
      "Generation 32, Best Fitness: 31.977030280664636\n",
      "Generation 33, Best Fitness: 33.427448465961845\n",
      "Generation 34, Best Fitness: 35.41427140562561\n",
      "Generation 35, Best Fitness: 36.7867444618896\n",
      "Generation 36, Best Fitness: 39.624857502170165\n",
      "Generation 37, Best Fitness: 42.1113912761685\n",
      "Generation 38, Best Fitness: 44.38450093963155\n",
      "Generation 39, Best Fitness: 45.1920495217982\n",
      "Generation 40, Best Fitness: 46.72038155012225\n",
      "Generation 41, Best Fitness: 49.343630686111766\n",
      "Generation 42, Best Fitness: 52.52641573477646\n",
      "Generation 43, Best Fitness: 54.44099820601293\n",
      "Generation 44, Best Fitness: 57.58547403528171\n",
      "Generation 45, Best Fitness: 60.59973611085626\n",
      "Generation 46, Best Fitness: 63.759893771400684\n",
      "Generation 47, Best Fitness: 67.38349615418876\n",
      "Generation 48, Best Fitness: 68.6634828064617\n",
      "Generation 49, Best Fitness: 71.45689841324956\n",
      "Generation 50, Best Fitness: 75.59792699261223\n",
      "Generation 51, Best Fitness: 77.1862328628181\n",
      "Generation 52, Best Fitness: 79.94241323921723\n",
      "Generation 53, Best Fitness: 81.9134340205146\n",
      "Generation 54, Best Fitness: 85.19519311064768\n",
      "Generation 55, Best Fitness: 85.93663218508979\n",
      "Generation 56, Best Fitness: 88.12797852299724\n",
      "Generation 57, Best Fitness: 90.66192406182913\n",
      "Generation 58, Best Fitness: 95.234360764832\n",
      "Generation 59, Best Fitness: 96.99511943429621\n",
      "Generation 60, Best Fitness: 100.82003971694645\n",
      "Generation 61, Best Fitness: 103.85460039672557\n",
      "Generation 62, Best Fitness: 106.63468503037913\n",
      "Generation 63, Best Fitness: 108.82364224688732\n",
      "Generation 64, Best Fitness: 112.96892661447582\n",
      "Generation 65, Best Fitness: 118.36384896077227\n",
      "Generation 66, Best Fitness: 121.38332796470132\n",
      "Generation 67, Best Fitness: 125.58426186905888\n",
      "Generation 68, Best Fitness: 129.67677553745546\n",
      "Generation 69, Best Fitness: 133.14963935910092\n",
      "Generation 70, Best Fitness: 137.6779429071759\n",
      "Generation 71, Best Fitness: 138.00536032779456\n",
      "Generation 72, Best Fitness: 141.48553658079396\n",
      "Generation 73, Best Fitness: 143.20154110515247\n",
      "Generation 74, Best Fitness: 144.84703184937464\n",
      "Generation 75, Best Fitness: 148.54449806252882\n",
      "Generation 76, Best Fitness: 153.34309093130003\n",
      "Generation 77, Best Fitness: 158.40121277193086\n",
      "Generation 78, Best Fitness: 164.5058269010549\n",
      "Generation 79, Best Fitness: 167.49514910261829\n",
      "Generation 80, Best Fitness: 176.30512864530988\n",
      "Generation 81, Best Fitness: 179.09216175396523\n",
      "Generation 82, Best Fitness: 183.26768927924087\n",
      "Generation 83, Best Fitness: 186.18441343718843\n",
      "Generation 84, Best Fitness: 190.22003017796504\n",
      "Generation 85, Best Fitness: 193.0890438374106\n",
      "Generation 86, Best Fitness: 196.51212178525017\n",
      "Generation 87, Best Fitness: 201.37944861109978\n",
      "Generation 88, Best Fitness: 204.6523102599638\n",
      "Generation 89, Best Fitness: 207.25288204899888\n",
      "Generation 90, Best Fitness: 209.55802727956552\n",
      "Generation 91, Best Fitness: 213.39577609022302\n",
      "Generation 92, Best Fitness: 215.71474281184288\n",
      "Generation 93, Best Fitness: 221.6916314416724\n",
      "Generation 94, Best Fitness: 225.47267123168433\n",
      "Generation 95, Best Fitness: 231.38385024470566\n",
      "Generation 96, Best Fitness: 240.0040482045551\n",
      "Generation 97, Best Fitness: 245.1843550924383\n",
      "Generation 98, Best Fitness: 249.0259749971327\n",
      "Generation 99, Best Fitness: 258.6910797708465\n",
      "Generation 100, Best Fitness: 263.0456542292958\n",
      "Final Best Solution: 16.21868225933586\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the fitness function\n",
    "def fitness(x):\n",
    "  # Maximize the function f(x) = x^2\n",
    "  return x**2\n",
    "\n",
    "# Define the GA parameters\n",
    "POP_SIZE = 100\n",
    "GENS = 100\n",
    "CROSSOVER_PROB = 0.8\n",
    "MUTATION_PROB = 0.2\n",
    "\n",
    "# Initialize the population\n",
    "pop = np.random.rand(POP_SIZE)\n",
    "\n",
    "# Evaluate the fitness of the initial population\n",
    "fitness_values = np.array([fitness(x) for x in pop])\n",
    "\n",
    "# Main GA loop\n",
    "for gen in range(GENS):\n",
    "    # Selection\n",
    "    parents = np.array([pop[np.argmax(fitness_values)] for _ in range(POP_SIZE//2)])\n",
    "\n",
    "    # Crossover\n",
    "    offspring = []\n",
    "    for _ in range(POP_SIZE//2):\n",
    "        parent1, parent2 = parents[np.random.randint(0, len(parents), 2)]\n",
    "        child = (parent1 + parent2) / 2\n",
    "        offspring.append(child)\n",
    "\n",
    "    # Mutation\n",
    "    for i in range(len(offspring)):  # Iterate over the correct range of offspring\n",
    "        if np.random.rand() < MUTATION_PROB:\n",
    "            offspring[i] += np.random.normal(0, 0.1)\n",
    "\n",
    "    # Replace the population with the new offspring\n",
    "    pop = offspring\n",
    "\n",
    "    # Evaluate the fitness of the new population\n",
    "    fitness_values = np.array([fitness(x) for x in pop])\n",
    "\n",
    "    # Print the best fitness value\n",
    "    print(f\"Generation {gen+1}, Best Fitness: {np.max(fitness_values)}\")\n",
    "# Print the final best solution\n",
    "print(f\"Final Best Solution: {pop[np.argmax(fitness_values)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use Genetic Algorithms in ML?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of GA for feature selection in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Individual: [0, 0, 1, 1]\n",
      "Best Fitness: 0.9666666666666668\n",
      "Selected Features: [[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.7 0.4]\n",
      " [1.4 0.3]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.1]\n",
      " [1.5 0.2]\n",
      " [1.6 0.2]\n",
      " [1.4 0.1]\n",
      " [1.1 0.1]\n",
      " [1.2 0.2]\n",
      " [1.5 0.4]\n",
      " [1.3 0.4]\n",
      " [1.4 0.3]\n",
      " [1.7 0.3]\n",
      " [1.5 0.3]\n",
      " [1.7 0.2]\n",
      " [1.5 0.4]\n",
      " [1.  0.2]\n",
      " [1.7 0.5]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.4]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [1.5 0.4]\n",
      " [1.5 0.1]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.2 0.2]\n",
      " [1.3 0.2]\n",
      " [1.4 0.1]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.3 0.3]\n",
      " [1.3 0.3]\n",
      " [1.3 0.2]\n",
      " [1.6 0.6]\n",
      " [1.9 0.4]\n",
      " [1.4 0.3]\n",
      " [1.6 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [4.7 1.4]\n",
      " [4.5 1.5]\n",
      " [4.9 1.5]\n",
      " [4.  1.3]\n",
      " [4.6 1.5]\n",
      " [4.5 1.3]\n",
      " [4.7 1.6]\n",
      " [3.3 1. ]\n",
      " [4.6 1.3]\n",
      " [3.9 1.4]\n",
      " [3.5 1. ]\n",
      " [4.2 1.5]\n",
      " [4.  1. ]\n",
      " [4.7 1.4]\n",
      " [3.6 1.3]\n",
      " [4.4 1.4]\n",
      " [4.5 1.5]\n",
      " [4.1 1. ]\n",
      " [4.5 1.5]\n",
      " [3.9 1.1]\n",
      " [4.8 1.8]\n",
      " [4.  1.3]\n",
      " [4.9 1.5]\n",
      " [4.7 1.2]\n",
      " [4.3 1.3]\n",
      " [4.4 1.4]\n",
      " [4.8 1.4]\n",
      " [5.  1.7]\n",
      " [4.5 1.5]\n",
      " [3.5 1. ]\n",
      " [3.8 1.1]\n",
      " [3.7 1. ]\n",
      " [3.9 1.2]\n",
      " [5.1 1.6]\n",
      " [4.5 1.5]\n",
      " [4.5 1.6]\n",
      " [4.7 1.5]\n",
      " [4.4 1.3]\n",
      " [4.1 1.3]\n",
      " [4.  1.3]\n",
      " [4.4 1.2]\n",
      " [4.6 1.4]\n",
      " [4.  1.2]\n",
      " [3.3 1. ]\n",
      " [4.2 1.3]\n",
      " [4.2 1.2]\n",
      " [4.2 1.3]\n",
      " [4.3 1.3]\n",
      " [3.  1.1]\n",
      " [4.1 1.3]\n",
      " [6.  2.5]\n",
      " [5.1 1.9]\n",
      " [5.9 2.1]\n",
      " [5.6 1.8]\n",
      " [5.8 2.2]\n",
      " [6.6 2.1]\n",
      " [4.5 1.7]\n",
      " [6.3 1.8]\n",
      " [5.8 1.8]\n",
      " [6.1 2.5]\n",
      " [5.1 2. ]\n",
      " [5.3 1.9]\n",
      " [5.5 2.1]\n",
      " [5.  2. ]\n",
      " [5.1 2.4]\n",
      " [5.3 2.3]\n",
      " [5.5 1.8]\n",
      " [6.7 2.2]\n",
      " [6.9 2.3]\n",
      " [5.  1.5]\n",
      " [5.7 2.3]\n",
      " [4.9 2. ]\n",
      " [6.7 2. ]\n",
      " [4.9 1.8]\n",
      " [5.7 2.1]\n",
      " [6.  1.8]\n",
      " [4.8 1.8]\n",
      " [4.9 1.8]\n",
      " [5.6 2.1]\n",
      " [5.8 1.6]\n",
      " [6.1 1.9]\n",
      " [6.4 2. ]\n",
      " [5.6 2.2]\n",
      " [5.1 1.5]\n",
      " [5.6 1.4]\n",
      " [6.1 2.3]\n",
      " [5.6 2.4]\n",
      " [5.5 1.8]\n",
      " [4.8 1.8]\n",
      " [5.4 2.1]\n",
      " [5.6 2.4]\n",
      " [5.1 2.3]\n",
      " [5.1 1.9]\n",
      " [5.9 2.3]\n",
      " [5.7 2.5]\n",
      " [5.2 2.3]\n",
      " [5.  1.9]\n",
      " [5.2 2. ]\n",
      " [5.4 2.3]\n",
      " [5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Define the number of features to select\n",
    "num_features = 3\n",
    "\n",
    "# Define the fitness function\n",
    "def fitness(individual):\n",
    "\n",
    "    # Select the features based on the individual\n",
    "    selected_indices = [i for i, x in enumerate(individual) if x == 1]\n",
    "    \n",
    "    # Handle the case where no features are selected\n",
    "    if not selected_indices:\n",
    "        return 0,  # Return a low fitness value if no features are selected\n",
    "    selected_features = np.array([X[:, i] for i in selected_indices]).T\n",
    "    \n",
    "    # Create a random forest classifier with the selected features\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    \n",
    "    # Evaluate the model using cross-validation\n",
    "    scores = cross_val_score(clf, selected_features, y, cv=5)\n",
    "    \n",
    "    # Return the mean score as the fitness value\n",
    "    return np.mean(scores),\n",
    "\n",
    "# Create a DEAP creator for the fitness function\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# Create a DEAP toolbox for the GA\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", np.random.choice, [0, 1])\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X[0]))\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", fitness)\n",
    "\n",
    "# Create a population of 50 individuals\n",
    "pop = toolbox.population(n=50)\n",
    "\n",
    "# Evaluate the initial population\n",
    "fitnesses = toolbox.map(toolbox.evaluate, pop)\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "# Run the GA for 20 generations\n",
    "for g in range(20):\n",
    "    offspring = algorithms.varAnd(pop, toolbox, cxpb=0.5, mutpb=0.1)\n",
    "    fits = toolbox.map(toolbox.evaluate, offspring)\n",
    "    for fit, ind in zip(fits, offspring):\n",
    "        ind.fitness.values = fit\n",
    "    pop = toolbox.select(offspring, k=len(pop))\n",
    "\n",
    "# Print the best individual and the corresponding fitness value\n",
    "best_individual = tools.selBest(pop, k=1)[0]\n",
    "print(\"Best Individual:\", best_individual)\n",
    "print(\"Best Fitness:\", best_individual.fitness.values[0])\n",
    "\n",
    "# Select the features based on the best individual\n",
    "selected_features = np.array([X[:, i] for i, x in enumerate(best_individual) if x == 1]).T\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GeneticðŸ§¬Algorithm: Complete Guide With Python Implementation](https://levelup.gitconnected.com/genetic-algorithm-complete-guide-with-python-implementation-747d62dbe9bd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
